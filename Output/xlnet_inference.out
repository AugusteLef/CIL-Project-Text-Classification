Sender: LSF System <lsfadmin@lo-s4-075>
Subject: Job 16524263: <python3 inference.py Data/test_data_basic.txt Predictions/xlnet_test.csv -dt Pretrained_Models/xlnet-base-cased/ -dm Models/xlnet-base-cased_basic_small/checkpoint_2/ -v -x> in cluster <leonhard> Done

Job <python3 inference.py Data/test_data_basic.txt Predictions/xlnet_test.csv -dt Pretrained_Models/xlnet-base-cased/ -dm Models/xlnet-base-cased_basic_small/checkpoint_2/ -v -x> was submitted from host <lo-login-02> by user <haslebas> in cluster <leonhard> at Fri Jun 25 13:52:45 2021
Job was executed on host(s) <lo-s4-075>, in queue <gpu.4h>, as user <haslebas> in cluster <leonhard> at Fri Jun 25 13:53:12 2021
</cluster/home/haslebas> was used as the home directory.
</cluster/home/haslebas/CIL-Project-Text-Classification> was used as the working directory.
Started at Fri Jun 25 13:53:12 2021
Terminated at Fri Jun 25 13:53:39 2021
Results reported at Fri Jun 25 13:53:39 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python3 inference.py Data/test_data_basic.txt Predictions/xlnet_test.csv -dt Pretrained_Models/xlnet-base-cased/ -dm Models/xlnet-base-cased_basic_small/checkpoint_2/ -v -x
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   24.46 sec.
    Max Memory :                                 4315 MB
    Average Memory :                             463.00 MB
    Total Requested Memory :                     8192.00 MB
    Delta Memory :                               3877.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                5
    Run time :                                   26 sec.
    Turnaround time :                            54 sec.

The output (if any) follows:

reading data...
loading tokenizer...
inference...
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
writing output...
